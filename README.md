TitanCore ğŸš€





TitanCore is a lightweight, high-performance modular AI inference engine designed for multimodal capabilities (Text, Vision, and Audio).

> ğŸ’¡ Fun Fact:
This engine was entirely architected and developed on a mobile device.




---

âš ï¸ Project Status & Tokenization

Training Status:
Structural framework only. NOT fully trained.

Tokenization:
Custom vocab.json + merges.txt
~400,000 tokens (4 Lakh)

Note:
Specialized fast GPU inference (not trillion-token model)



---

ğŸ—ï¸ System Architecture

Core-1/
â”œâ”€â”€ core/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Neural brain
â”‚Â  Â â”œâ”€â”€ model/
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ gpt.cppÂ  Â  Â  Â  Â  Â  Â # Transformer decoder
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ attention.cuÂ  Â  Â  Â  # FlashAttention CUDA kernel
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ block.cppÂ  Â  Â  Â  Â  Â # Transformer blocks
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ embedding.cppÂ  Â  Â  Â # Token + position embedding
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ kv_cache.cppÂ  Â  Â  Â  # KV memory
â”‚Â  Â â”‚Â  Â â””â”€â”€ sampler.cppÂ  Â  Â  Â  Â # top-k / top-p / temp
â”‚Â  Â â”‚
â”‚Â  Â â”œâ”€â”€ tokenizer/
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ sentencepiece.cpp
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ vocab.json
â”‚Â  Â â”‚Â  Â â””â”€â”€ merges.txt
â”‚Â  Â â”‚
â”‚Â  Â â”œâ”€â”€ vision/Â  Â  Â  Â  Â  Â  Â  Â  Â # multimodal
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ vit.cppÂ  Â  Â  Â  Â  Â  Â # vision transformer
â”‚Â  Â â”‚Â  Â â””â”€â”€ clip.cpp
â”‚Â  Â â”‚
â”‚Â  Â â”œâ”€â”€ audio/
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ whisper.cpp
â”‚Â  Â â”‚Â  Â â””â”€â”€ mel.cpp
â”‚Â  Â â”‚
â”‚Â  Â â””â”€â”€ runtime/
â”‚Â  Â  Â  Â â”œâ”€â”€ engine.cppÂ  Â  Â  Â  Â  # inference engine
â”‚Â  Â  Â  Â â”œâ”€â”€ scheduler.cppÂ  Â  Â  Â # batching
â”‚Â  Â  Â  Â â””â”€â”€ memory.cppÂ  Â  Â  Â  Â  # VRAM manager
â”‚
â”œâ”€â”€ distributed/
â”‚Â  Â â”œâ”€â”€ nccl.cppÂ  Â  Â  Â  Â  Â  Â  Â  # tensor parallel
â”‚Â  Â â”œâ”€â”€ fsdp.cppÂ  Â  Â  Â  Â  Â  Â  Â  # shard weights
â”‚Â  Â â””â”€â”€ mpi.cpp
â”‚
â”œâ”€â”€ quant/
â”‚Â  Â â”œâ”€â”€ int8.cpp
â”‚Â  Â â”œâ”€â”€ int4.cpp
â”‚Â  Â â””â”€â”€ fp8.cpp
â”‚
â”œâ”€â”€ retrieval/Â  Â  Â  Â  Â  Â  Â  Â  Â  # RAG
â”‚Â  Â â”œâ”€â”€ faiss.cpp
â”‚Â  Â â”œâ”€â”€ embedder.cpp
â”‚Â  Â â””â”€â”€ loader.cpp
â”‚
â”œâ”€â”€ safety/
â”‚Â  Â â”œâ”€â”€ moderation.cpp
â”‚Â  Â â”œâ”€â”€ jailbreak.cpp
â”‚Â  Â â””â”€â”€ rate_limit.cpp
â”‚
â”œâ”€â”€ api/
â”‚Â  Â â”œâ”€â”€ server.cppÂ  Â  Â  Â  Â  Â  Â  # REST / gRPC
â”‚Â  Â â”œâ”€â”€ routes.cpp
â”‚Â  Â â””â”€â”€ auth.cpp
â”‚
â”œâ”€â”€ monitoring/
â”‚Â  Â â”œâ”€â”€ prometheus.cpp
â”‚Â  Â â””â”€â”€ metrics.cpp
â”‚
â”œâ”€â”€ tools/
â”‚Â  Â â”œâ”€â”€ convert_weights.py
â”‚Â  Â â”œâ”€â”€ benchmark.cpp
â”‚Â  Â â””â”€â”€ profiler.cpp
â”‚
â”œâ”€â”€ configs/
â”‚Â  Â â”œâ”€â”€ gpt4o.yaml
â”‚Â  Â â”œâ”€â”€ cluster.yaml
â”‚Â  Â â””â”€â”€ safety.yaml
â”‚
â”œâ”€â”€ weights/
â”‚Â  Â â””â”€â”€ titancore.gguf
â”‚
â”œâ”€â”€ main.cppÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  # system bootstrap
â””â”€â”€ CMakeLists.txt


---

ğŸ› ï¸ Technical Specifications

Development Platform : Android / Termux
Vocabulary Size      : ~400,000
Model Format         : GGUF (titancore.gguf)
Core Inference       : C++17 Transformer
Acceleration         : FlashAttention CUDA
Precision            : FP32 / FP16 / INT8 / INT4


---

ğŸš€ Getting Started

Prerequisites:

CMake 3.18+

CUDA Toolkit

C++17 Compiler

NVIDIA GPU (CPU NOT supported)


Build:

git clone https://github.com/litonsarkar3988-max/Core-1
cd titancore

mkdir build && cd build
cmake ..
make -j$(nproc)

Run (GPU Only):

./main --model ../weights/titancore.gguf --config ../configs/gpt4o.yaml


---

ğŸ›¡ï¸ Safety

Moderation + jailbreak detection included.


---

âš ï¸ Important

Inference only

Requires pretrained weights

GPU mandatory

Tokenizer ~400k

Experimental research project



---

ğŸ‘¥ Author

Rahul Sarkar â€” India ğŸ‡®ğŸ‡³
Personal AI research project developed entirely on mobile.
